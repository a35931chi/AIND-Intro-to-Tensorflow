{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello, Tensor World!\n",
    "\n",
    "Let’s analyze the Hello World script you ran. For reference, I’ve added the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow object called hello_constant\n",
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor\n",
    "\n",
    "In TensorFlow, data isn’t stored as integers, floats, or strings. These values are encapsulated in an object called a tensor. In the case of hello_constant = tf.constant('Hello World!'), hello_constant is a 0-dimensional string tensor, but tensors come in a variety of sizes as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is a 0-dimensional int32 tensor\n",
    "A = tf.constant(1234) \n",
    "# B is a 1-dimensional int32 tensor\n",
    "B = tf.constant([123,456,789]) \n",
    "# C is a 2-dimensional int32 tensor\n",
    "C = tf.constant([ [123,456,789], [222,333,444] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"TensorFlow Session\" is an environment for running a graph. The session is in charge of allocating the operations to GPU(s) and/or CPU(s), including remote machines. Let’s see how you use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.placeholder()\n",
    "\n",
    "Sadly you can’t just set x to your dataset and put it in TensorFlow, because over time you'll want your TensorFlow model to take in different datasets with different parameters. You need tf.placeholder()!\n",
    "\n",
    "tf.placeholder() returns a tensor that gets its value from data passed to the tf.session.run() function, allowing you to set the input right before the session runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Hello World'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the feed_dict parameter in tf.session.run() to set the placeholder tensor. The above example shows the tensor x being set to the string \"Hello, world\". It's also possible to set more than one tensor using feed_dict as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Test String', y: 123, z: 45.67})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow Math\n",
    "\n",
    "Getting the input is great, but now you need to use it. You're going to use basic math functions that everyone knows and loves - add, subtract, multiply, and divide - with tensors. (There's many more math functions you can check out in the documentation.) https://www.tensorflow.org/api_guides/python/math_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.add(5, 2)  # 7\n",
    "x = tf.subtract(10, 4) # 6\n",
    "y = tf.multiply(2, 5)  # 10\n",
    "y = tf.divide(2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting types\n",
    "\n",
    "It may be necessary to convert between types to make certain operators work together. For example, if you tried the following, it would fail with an exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sub:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.subtract(tf.cast(tf.constant(2.0), tf.int32), tf.constant(1))   # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.Variable class creates a tensor with an initial value that can be modified, much like a normal Python variable. This tensor stores its state in the session, so you must initialize the state of the tensor manually. You'll use the tf.global_variables_initializer() function to initialize the state of all the Variable tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(5)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to leverage a normal distribution\n",
    "n_features = 120\n",
    "n_labels = 5\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get some zeros\n",
    "n_labels = 5\n",
    "bias = tf.Variable(tf.zeros(n_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow Softmax\n",
    "\n",
    "We're using TensorFlow to build neural networks and, appropriately, there's a function for calculating softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.nn.softmax([2.0, 1.0, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to calculate cross entropy, there are some things we need\n",
    "1. equation: -sum(y*log(yhat))\n",
    "2. softmax\n",
    "3. log\n",
    "4. reduce sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reduce_sum([1, 2, 3, 4, 5])\n",
    "x = tf.log(100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.356675\n"
     ]
    }
   ],
   "source": [
    "#cross entropy example\n",
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "one_hot_data = [1.0, 0.0, 0.0]\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(tf.multiply(one_hot, tf.log(softmax)))\n",
    "\n",
    "# TODO: Print cross entropy from session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    output = sess.run(cross_entropy, feed_dict = {softmax: softmax_data, one_hot: one_hot_data})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-batching\n",
    "\n",
    "Mini-batching is a technique for training on subsets of the dataset instead of all the data at one time. This provides the ability to train a model, even if a computer lacks the memory to store the entire dataset.\n",
    "\n",
    "Mini-batching is computationally inefficient, since you can't calculate the loss simultaneously across all samples. However, this is a small price to pay in order to be able to run the model at all.\n",
    "\n",
    "It's also quite useful combined with SGD. The idea is to randomly shuffle the data at the start of each epoch, then create the mini-batches. For each mini-batch, you train the network weights with gradient descent. Since these batches are random, you're performing SGD with each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    outout_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /datasets/ud730/mnist\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /datasets/ud730/mnist\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /datasets/ud730/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /datasets/ud730/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Test Accuracy: 0.16619999706745148\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "# TODO: Set batch size\n",
    "batch_size = 50\n",
    "assert batch_size is not None, 'You must set the batch size'\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # TODO: Train optimizer on all batches\n",
    "    for batch_features, batch_labels in batches(batch_size, train_features, train_labels):\n",
    "        sess.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "    \n",
    "    print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epochs\n",
    "\n",
    "An epoch is a single forward and backward pass of the whole dataset. This is used to increase the accuracy of the model without requiring more data. This section will cover epochs in TensorFlow and how to choose the right number of epochs.\n",
    "\n",
    "The following TensorFlow code trains a model using 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /datasets/ud730/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0    - Cost: 13.3     Valid Accuracy: 0.104\n",
      "Epoch: 1    - Cost: 11.8     Valid Accuracy: 0.137\n",
      "Epoch: 2    - Cost: 10.7     Valid Accuracy: 0.165\n",
      "Epoch: 3    - Cost: 9.94     Valid Accuracy: 0.182\n",
      "Epoch: 4    - Cost: 9.29     Valid Accuracy: 0.196\n",
      "Epoch: 5    - Cost: 8.76     Valid Accuracy: 0.208\n",
      "Epoch: 6    - Cost: 8.33     Valid Accuracy: 0.222\n",
      "Epoch: 7    - Cost: 7.97     Valid Accuracy: 0.237\n",
      "Epoch: 8    - Cost: 7.67     Valid Accuracy: 0.253\n",
      "Epoch: 9    - Cost: 7.42     Valid Accuracy: 0.266\n",
      "Test Accuracy: 0.2782999873161316\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def print_epoch_stats(epoch_i, sess, last_features, last_labels):\n",
    "    \"\"\"\n",
    "    Print cost and validation accuracy of an epoch\n",
    "    \"\"\"\n",
    "    current_cost = sess.run(\n",
    "        cost,\n",
    "        feed_dict={features: last_features, labels: last_labels})\n",
    "    valid_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: valid_features, labels: valid_labels})\n",
    "    print('Epoch: {:<4} - Cost: {:<8.3} Valid Accuracy: {:<5.3}'.format(\n",
    "        epoch_i,\n",
    "        current_cost,\n",
    "        valid_accuracy))\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "valid_features = mnist.validation.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "valid_labels = mnist.validation.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "learn_rate = 0.001\n",
    "\n",
    "train_batches = batches(batch_size, train_features, train_labels)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch_i in range(epochs):\n",
    "\n",
    "        # Loop over all batches\n",
    "        for batch_features, batch_labels in train_batches:\n",
    "            train_feed_dict = {\n",
    "                features: batch_features,\n",
    "                labels: batch_labels,\n",
    "                learning_rate: learn_rate}\n",
    "            sess.run(optimizer, feed_dict=train_feed_dict)\n",
    "\n",
    "        # Print cost and validation accuracy of an epoch\n",
    "        print_epoch_stats(epoch_i, sess, batch_features, batch_labels)\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow ReLUs\n",
    "\n",
    "TensorFlow provides the ReLU function as tf.nn.relu(), as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.11000013   8.44000053]\n",
      " [  0.           0.        ]\n",
      " [ 24.01000214  38.23999786]]\n"
     ]
    }
   ],
   "source": [
    "# a quick application on the relu function\n",
    "import tensorflow as tf\n",
    "\n",
    "output = None\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[1.0, 2.0, 3.0, 4.0], [-1.0, -2.0, -3.0, -4.0], [11.0, 12.0, 13.0, 14.0]])\n",
    "# TODO: Create Model\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0]) #note that the feature comes first, weights come second.\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
    "# TODO: Print session results\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will now step through the tensorflow MNIST exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting .\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting .\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting .\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting .\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#download data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define learning parameters\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 128  # Decrease batch size if you don't have enough memory\n",
    "display_step = 1\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden layer parameter\n",
    "n_hidden_layer = 256 # layer number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it's kinda weird that weights and biases are defined this way\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define input\n",
    "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "x_flat = tf.reshape(x, [-1, n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layer with RELU activation\n",
    "layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer']),\\\n",
    "    biases['hidden_layer'])\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "# Output layer with linear activation\n",
    "logits = tf.add(tf.matmul(layer_1, weights['out']), biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and Restore TensorFlow Models\n",
    "\n",
    "Training a model can take hours. But once you close your TensorFlow session, you lose all the trained weights and biases. If you were to reuse the model in the future, you would have to train it all over again!\n",
    "\n",
    "Fortunately, TensorFlow gives you the ability to save your progress using a class called tf.train.Saver. This class provides the functionality to save any tf.Variable to your file system.\n",
    "Saving Variables\n",
    "\n",
    "Let's start with a simple example of saving weights and bias Tensors. For the first example you'll just save two variables. Later examples will save all the weights in a practical model.\n",
    "\n",
    "The Tensors weights and bias are set to random values using the tf.truncated_normal() function. The values are then saved to the save_file location, \"model.ckpt\", using the tf.train.Saver.save() function. (The \".ckpt\" extension stands for \"checkpoint\".)\n",
    "\n",
    "If you're using TensorFlow 0.11.0RC1 or newer, a file called \"model.ckpt.meta\" will also be created. This file contains the TensorFlow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[-0.6434446   0.21435103  0.16335282]\n",
      " [ 1.17818832  1.76511431  0.37516695]]\n",
      "Bias:\n",
      "[-0.31363833 -0.15285458  1.14120078]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# The file path to save the data\n",
    "save_file = os.path.join(os.getcwd(), 'model.ckpt')\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all the Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weights:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\inves\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\Jupyter Notebook\\deep-learning-master\\intro-to-tensorflow\\model.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable, save/RestoreV2)]]\n\nCaused by op 'save/Assign', defined at:\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-5d4c1caf7a85>\", line 10, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 270, in assign\n    validate_shape=validate_shape)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable, save/RestoreV2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable, save/RestoreV2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-5d4c1caf7a85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Load the weights and bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#not sure why this isn't working\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Show the values of weights and bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1457\u001b[1;33m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable, save/RestoreV2)]]\n\nCaused by op 'save/Assign', defined at:\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-5d4c1caf7a85>\", line 10, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 270, in assign\n    validate_shape=validate_shape)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable, save/RestoreV2)]]\n"
     ]
    }
   ],
   "source": [
    "#loading variables\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, save_file) #not sure why this isn't working\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a Trained Model\n",
    "\n",
    "Let's see how to train a model and save its weights.\n",
    "\n",
    "First start with a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\train-images-idx3-ubyte.gz\n",
      "Extracting .\\train-labels-idx1-ubyte.gz\n",
      "Extracting .\\t10k-images-idx3-ubyte.gz\n",
      "Extracting .\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Remove previous Tensors and Operations\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Validation Accuracy: 0.07699999958276749\n",
      "Epoch 10  - Validation Accuracy: 0.219200000166893\n",
      "Epoch 20  - Validation Accuracy: 0.38019999861717224\n",
      "Epoch 30  - Validation Accuracy: 0.492000013589859\n",
      "Epoch 40  - Validation Accuracy: 0.5562000274658203\n",
      "Epoch 50  - Validation Accuracy: 0.6060000061988831\n",
      "Epoch 60  - Validation Accuracy: 0.642799973487854\n",
      "Epoch 70  - Validation Accuracy: 0.6743999719619751\n",
      "Epoch 80  - Validation Accuracy: 0.6955999732017517\n",
      "Epoch 90  - Validation Accuracy: 0.715399980545044\n",
      "Trained Model Saved.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "save_file = os.path.join(os.getcwd(), 'train_model.ckpt')\n",
    "batch_size = 128\n",
    "n_epochs = 100\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(n_epochs):\n",
    "        total_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_features, batch_labels = mnist.train.next_batch(batch_size)\n",
    "            sess.run(\n",
    "                optimizer,\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Print status for every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            valid_accuracy = sess.run(\n",
    "                accuracy,\n",
    "                feed_dict={\n",
    "                    features: mnist.validation.images,\n",
    "                    labels: mnist.validation.labels})\n",
    "            print('Epoch {:<3} - Validation Accuracy: {}'.format(\n",
    "                epoch,\n",
    "                valid_accuracy))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)\n",
    "    print('Trained Model Saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a Trained Model\n",
    "\n",
    "Let's load the weights and bias from memory, then check the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\inves\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\Jupyter Notebook\\deep-learning-master\\intro-to-tensorflow\\train_model.ckpt\n",
      "Test Accuracy: 0.7253999710083008\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: mnist.test.images, labels: mnist.test.labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Weights and Biases into a New Model\n",
    "\n",
    "Sometimes you might want to adjust, or \"finetune\" a model that you have already trained and saved.\n",
    "\n",
    "However, loading saved Variables directly into a modified model can generate errors. Let's go over how to avoid these problems. \n",
    "\n",
    "Naming Error\n",
    "\n",
    "TensorFlow uses a string identifier for Tensors and Operations called name. If a name is not given, TensorFlow will create one automatically. TensorFlow will give the first node the name <Type>, and then give the name <Type>_<number> for the subsequent nodes. Let's see how this can affect loading a model with a different order of weights and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Weights: Variable:0\n",
      "Save Bias: Variable_1:0\n",
      "Load Weights: Variable_1:0\n",
      "Load Bias: Variable:0\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\inves\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\Jupyter Notebook\\deep-learning-master\\intro-to-tensorflow\\model.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[Node: save/Assign_1 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1, save/RestoreV2_1)]]\n\nCaused by op 'save/Assign_1', defined at:\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-56044e6ea436>\", line 29, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 270, in assign\n    validate_shape=validate_shape)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[Node: save/Assign_1 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1, save/RestoreV2_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[Node: save/Assign_1 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1, save/RestoreV2_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-56044e6ea436>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# Load the weights and bias - ERROR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1457\u001b[1;33m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[Node: save/Assign_1 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1, save/RestoreV2_1)]]\n\nCaused by op 'save/Assign_1', defined at:\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-56044e6ea436>\", line 29, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 270, in assign\n    validate_shape=validate_shape)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[Node: save/Assign_1 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1, save/RestoreV2_1)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "save_file = os.path.join(os.getcwd(), 'model.ckpt')\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Save Weights: {}'.format(weights.name))\n",
    "print('Save Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, save_file)\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Load Weights: {}'.format(weights.name))\n",
    "print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias - ERROR\n",
    "    saver.restore(sess, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Weights: weights_0:0\n",
      "Save Bias: bias_0:0\n",
      "Load Weights: weights_0:0\n",
      "Load Bias: bias_0:0\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\inves\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\Jupyter Notebook\\deep-learning-master\\intro-to-tensorflow\\model.ckpt\n",
      "Loaded Weights and Bias successfully.\n"
     ]
    }
   ],
   "source": [
    "#Instead of letting TensorFlow set the name property, let's set it manually:\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "save_file = os.path.join(os.getcwd(), 'model.ckpt')\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Save Weights: {}'.format(weights.name))\n",
    "print('Save Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, save_file)\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]) ,name='weights_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Load Weights: {}'.format(weights.name))\n",
    "print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias - No Error\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "print('Loaded Weights and Bias successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32) # probability to keep units\n",
    "\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.57999945   8.45999908]\n",
      " [  0.           0.        ]\n",
      " [ 33.74000168  43.38000107]]\n"
     ]
    }
   ],
   "source": [
    "#examples of how th dropout would work\n",
    "# Solution is available in the other \"solution.py\" tab\n",
    "import tensorflow as tf\n",
    "\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[0.0, 2.0, 3.0, 4.0], [0.1, 0.2, 0.3, 0.4], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model with Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Print logits from a session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(logits, feed_dict={keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
